
# Books
* Getting things done
* How to become a straight A student

# Papers
* [[Non-local module]]
* [[Squeeze-and-Excitation]]
* [Transformers in Vision: A survey](https://dl.acm.org/doi/full/10.1145/3505244?casa_token=saxBnFUXs6AAAAAA%3AdyyVFhzeULZPNbEHCFSDh1fYUzs47-smeiLpJA1j7_sdWR9EenqAxFShDwDAHWGD7TCiBpICVrE6)
* [Typicality in generative models](https://benanne.github.io/2020/09/01/typicality.html)
	* Cited in Stable diffusion paper, looks very interesting
	* This is the paper they cited when they mentioned that likelihood-based models spend excessive capacity modeling imperceptible details of the data. Why is this? Hopefully explained here.
* [DDPMs](https://arxiv.org/abs/2006.11239)
	* This is the OG paper, and there is stuff in here you do not know, but should know
* [The unreasonable effectiveness of deep features as a perceptual metric](https://arxiv.org/abs/1801.03924)
	* Part of the loss function of the autoencoder in stable diffusion
* 
